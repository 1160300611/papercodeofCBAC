{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T01:31:31.740094Z",
     "start_time": "2020-07-07T01:31:24.786738Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import networkx as nx\n",
    "# import openne\n",
    "import network_embedding.classify\n",
    "import network_embedding.gf\n",
    "import network_embedding.graph\n",
    "import network_embedding.grarep\n",
    "import network_embedding.hope\n",
    "import network_embedding.lap\n",
    "import network_embedding.line\n",
    "import network_embedding.lle\n",
    "import network_embedding.node2vec\n",
    "import network_embedding.sdne\n",
    "import network_embedding.tadw\n",
    "import network_embedding.walker\n",
    "from network_embedding.graph import *\n",
    "# from network_embedding import *\n",
    "# import openne.node2vec\n",
    "# from openne.graph import *\n",
    "import random\n",
    "random.seed(32)\n",
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T14:40:08.592620Z",
     "start_time": "2020-05-29T14:40:07.708308Z"
    }
   },
   "outputs": [],
   "source": [
    "#读取文件中的正负边\n",
    "def read_edges(filename):\n",
    "    pos_edges=set()\n",
    "    neg_edges=set()\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            node1 = words[0]\n",
    "            node2 = words[1]\n",
    "            label = words[2]\n",
    "            if label=='1':\n",
    "                pos_edges.add((node1,node2))\n",
    "            else:\n",
    "                neg_edges.add((node1,node2))\n",
    "#     print(\"{}\\n{}\".format(len(nodeList1),len(nodeList2)))\n",
    "    return list(pos_edges), list(neg_edges)\n",
    "\n",
    "\n",
    "# # 读取文件中的正负边\n",
    "# def read_edges(filename):\n",
    "#     pos_edges = set()\n",
    "#     neg_edges = set()\n",
    "#     with open(filename, 'r') as f:\n",
    "#         for line in f:\n",
    "#             words = line.split()\n",
    "#             node1 = words[0]\n",
    "#             node2 = words[1]\n",
    "#             label = words[2]\n",
    "#             if label == '1':\n",
    "#                 pos_edges.add((node1, node2))\n",
    "#             else:\n",
    "#                 neg_edges.add((node1, node2))\n",
    "# #     print(\"{}\\n{}\".format(len(nodeList1),len(nodeList2)))\n",
    "#     return list(pos_edges), list(neg_edges)\n",
    "\n",
    "\n",
    "# 提取图节点的node2vec表示向量\n",
    "def extract_node2vec(edgelist_file, node2vec_params, save_path):\n",
    "    #     input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "    network = Graph()\n",
    "    network.read_edgelist(filename=edgelist_file)\n",
    "    representation_size = node2vec_params['representation_size']  # 表征向量的长度\n",
    "    number_walks = node2vec_params['number_walks']  # 每个节点随机游走序列数量18\n",
    "    walk_length = node2vec_params['walk_length']  # 每个随机游走序列的长度100\n",
    "    workers = node2vec_params['workers']  # 并行数量\n",
    "    window_size = node2vec_params['window_size']  # skip-gram提取词的上下文数量16\n",
    "    # node2vec参数\n",
    "    q = node2vec_params['q']  # {0.25,0.50,1,2,4}\n",
    "    p = node2vec_params['p']\n",
    "    # deepwalk只需要令p=1,q=1\n",
    "    # 网络表征模型\n",
    "    embeddings = network_embedding.node2vec.Node2vec(graph=network, path_length=walk_length,\n",
    "                                          num_paths=number_walks, dim=representation_size,\n",
    "                                          workers=workers, p=p, q=q, window=window_size)\n",
    "    # 保存\n",
    "    embeddings.save_embeddings(save_path)\n",
    "    # 提取节点及其表示向量\n",
    "    embeddings = embeddings.vectors\n",
    "    return embeddings\n",
    "\n",
    "# 提取图节点的LINE表示向量\n",
    "\n",
    "\n",
    "def extract_LINE(edgelist_file, LINE_params, save_path):\n",
    "    #     input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "    network = Graph()\n",
    "    network.read_edgelist(filename=edgelist_file)\n",
    "    representation_size = LINE_params['representation_size']\n",
    "    order = LINE_params['order']\n",
    "    epochs = LINE_params['epochs']\n",
    "    # 网络表征模型\n",
    "    embeddings = network_embedding.line.LINE(\n",
    "        graph=network, epoch=epochs, rep_size=representation_size, order=order)\n",
    "    # 保存\n",
    "    embeddings.save_embeddings(save_path)\n",
    "    # 提取节点及其表示向量\n",
    "    embeddings = embeddings.vectors\n",
    "    return embeddings\n",
    "\n",
    "# 提取图节点的GraRep表示向量\n",
    "\n",
    "\n",
    "def extract_GraRep(edgelist_file, GraRep_params, save_path):\n",
    "    #     input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "    network = Graph()\n",
    "    network.read_edgelist(filename=edgelist_file)\n",
    "    representation_size = GraRep_params['representation_size']\n",
    "    kstep = GraRep_params['kstep']\n",
    "    # 网络表征模型\n",
    "    embeddings = network_embedding.grarep.GraRep(\n",
    "        graph=network, Kstep=kstep, dim=representation_size)\n",
    "    # 保存\n",
    "    embeddings.save_embeddings(save_path)\n",
    "    # 提取节点及其表示向量\n",
    "    embeddings = embeddings.vectors\n",
    "    return embeddings\n",
    "\n",
    "# 提取图节点的LLE表示向量\n",
    "\n",
    "\n",
    "def extract_LLE(edgelist_file, LLE_params, save_path):\n",
    "    #     input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "    network = Graph()\n",
    "    network.read_edgelist(filename=edgelist_file)\n",
    "    representation_size = LLE_params['representation_size']\n",
    "    # 网络表征模型\n",
    "    embeddings = network_embedding.lle.LLE(graph=network, d=representation_size)\n",
    "    # 保存\n",
    "    embeddings.save_embeddings(save_path)\n",
    "    # 提取节点及其表示向量\n",
    "    embeddings = embeddings.vectors\n",
    "    return embeddings\n",
    "\n",
    "# 提取图节点的HOPE表示向量\n",
    "\n",
    "\n",
    "def extract_HOPE(edgelist_file, HOPE_params, save_path):\n",
    "    #     input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "    network = Graph()\n",
    "    network.read_edgelist(filename=edgelist_file)\n",
    "    representation_size = HOPE_params['representation_size']\n",
    "    # 网络表征模型\n",
    "    embeddings = network_embedding.hope.HOPE(graph=network, d=representation_size)\n",
    "    # 保存\n",
    "    embeddings.save_embeddings(save_path)\n",
    "    # 提取节点及其表示向量\n",
    "    embeddings = embeddings.vectors\n",
    "    return embeddings\n",
    "\n",
    "# 提取图节点的SDNE表示向量\n",
    "\n",
    "\n",
    "def extract_SDNE(edgelist_file, SDNE_params, save_path):\n",
    "    #     input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "    network = Graph()\n",
    "    network.read_edgelist(filename=edgelist_file)\n",
    "\n",
    "    encoder_layer_list = ast.literal_eval(SDNE_params['encoder_list'])\n",
    "    representation_size = SDNE_params['representation_size']\n",
    "    epochs = SDNE_params['epochs']\n",
    "    bs = SDNE_params['bs']\n",
    "    lr = SDNE_params['lr']\n",
    "    nu1 = SDNE_params['nu1']\n",
    "    nu2 = SDNE_params['nu2']\n",
    "    beta = SDNE_params['beta']\n",
    "    alpha = SDNE_params['alpha']\n",
    "    # 网络表征模型\n",
    "    embeddings = network_embedding.sdne.SDNE(graph=network, encoder_layer_list=encoder_layer_list,\n",
    "                                  alpha=alpha, beta=beta, nu1=nu1, nu2=nu2,\n",
    "                                  batch_size=bs, epoch=epochs, learning_rate=lr)\n",
    "    # 保存\n",
    "    embeddings.save_embeddings(save_path)\n",
    "    # 提取节点及其表示向量\n",
    "    embeddings = embeddings.vectors\n",
    "    return embeddings\n",
    "\n",
    "# 提取图节点的LaplacianEigenmaps表示向量\n",
    "def extract_LaplacianEigenmaps(edgelist_file, LaplacianEigenmaps_params, save_path):\n",
    "    #     input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "    network = Graph()\n",
    "    network.read_edgelist(filename=edgelist_file)\n",
    "    representation_size = LaplacianEigenmaps_params['representation_size']\n",
    "    # 网络表征模型\n",
    "    embeddings = network_embedding.lap.LaplacianEigenmaps(\n",
    "        graph=network, rep_size=representation_size)\n",
    "    # 保存\n",
    "    embeddings.save_embeddings(save_path)\n",
    "    # 提取节点及其表示向量\n",
    "    embeddings = embeddings.vectors\n",
    "    return embeddings\n",
    "\n",
    "# 提取图节点的GraphFactorization表示向量\n",
    "def extract_GraphFactorization(edgelist_file, GraphFactorization_params, save_path):\n",
    "    #     input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "    network = Graph()\n",
    "    network.read_edgelist(filename=edgelist_file)\n",
    "    representation_size = GraphFactorization_params['representation_size']\n",
    "    epochs = GraphFactorization_params['epochs']\n",
    "    weight_decay = GraphFactorization_params['weight-decay']\n",
    "    lr = GraphFactorization_params['lr']\n",
    "    # 网络表征模型\n",
    "    embeddings = network_embedding.gf.GraphFactorization(graph=network, rep_size=representation_size,\n",
    "                                              epoch=epochs, learning_rate=lr, weight_decay=weight_decay)\n",
    "    # 保存\n",
    "    embeddings.save_embeddings(save_path)\n",
    "    # 提取节点及其表示向量\n",
    "    embeddings = embeddings.vectors\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T14:47:18.392Z"
    }
   },
   "outputs": [],
   "source": [
    "#1\n",
    "node2vec_params={\n",
    "    'representation_size':128, #表征向量的长度\n",
    "    'number_walks':40,  #每个节点随机游走序列数量18\n",
    "    'walk_length':10,   #每个随机游走序列的长度100\n",
    "    'workers':8,        #并行数量\n",
    "    'window_size':10,   #skip-gram提取词的上下文数量16\n",
    "    #node2vec参数\n",
    "    'q':0.25, # {0.25,0.50,1,2,4}\n",
    "    'p':0.25,\n",
    "    #deepwalk只需要令p=1,q=1\n",
    "}\n",
    "#2\n",
    "deepwalk_params={    \n",
    "    'representation_size':128, #表征向量的长度\n",
    "    'number_walks':40,  #每个节点随机游走序列数量18\n",
    "    'walk_length':10,   #每个随机游走序列的长度100\n",
    "    'workers':8,        #并行数量\n",
    "    'window_size':10,   #skip-gram提取词的上下文数量16\n",
    "    #node2vec参数\n",
    "    'q':1, # {0.25,0.50,1,2,4}\n",
    "    'p':1,\n",
    "    #deepwalk只需要令p=1,q=1\n",
    "}\n",
    "#3\n",
    "LINE_params={  \n",
    "    'representation_size':128, #表征向量的长度\n",
    "    'order':3,   \n",
    "    'epochs':8,\n",
    "}\n",
    "#4\n",
    "GraRep_params={    \n",
    "    'representation_size':128, #表征向量的长度\n",
    "    'kstep':8,\n",
    "}\n",
    "#5\n",
    "LLE_params={    \n",
    "    'representation_size':128, #表征向量的长度\n",
    "}\n",
    "#6\n",
    "HOPE_params={    \n",
    "    'representation_size':128, #表征向量的长度\n",
    "}\n",
    "#7\n",
    "SDNE_params={  \n",
    "    'encoder-list':'[1000, 128]', #表征向量的长度\n",
    "    'bs':200, \n",
    "    'epochs':8,\n",
    "    'lr':0.01,\n",
    "    'nu1':1e-5,  \n",
    "    'nu2':1e-4, \n",
    "    'beta':5.,  \n",
    "    'alpha':1e-6, \n",
    "}\n",
    "#8\n",
    "LaplacianEigenmaps_params={    \n",
    "    'representation_size':128, #表征向量的长度\n",
    "}\n",
    "#9\n",
    "GraphFactorization_params={    \n",
    "    'representation_size':128, #表征向量的长度\n",
    "    'epochs':8,\n",
    "    'weight-decay':5e-4,\n",
    "    'lr':0.01,\n",
    "}\n",
    "input_path=\"network_edgelist/all_network_edgelist.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T14:40:09.272250Z",
     "start_time": "2020-05-29T14:40:09.270069Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "# node2vec_embeddings_file=\"embeddings/all_network_node2vec128.txt\"\n",
    "# node2vec_embeddings=extract_node2vec(input_path, node2vec_params, node2vec_embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T14:40:14.551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t-0.02857142857142857\n",
      "  (0, 2)\t-0.02857142857142857\n",
      "  (0, 3)\t-0.02857142857142857\n",
      "  (0, 4)\t-0.02857142857142857\n",
      "  (0, 5)\t-0.02857142857142857\n",
      "  (0, 6)\t-0.02857142857142857\n",
      "  (0, 7)\t-0.02857142857142857\n",
      "  (0, 8)\t-0.02857142857142857\n",
      "  (0, 9)\t-0.02857142857142857\n",
      "  (0, 10)\t-0.02857142857142857\n",
      "  (0, 11)\t-0.02857142857142857\n",
      "  (0, 12)\t-0.02857142857142857\n",
      "  (0, 13)\t-0.02857142857142857\n",
      "  (0, 14)\t-0.02857142857142857\n",
      "  (0, 15)\t-0.02857142857142857\n",
      "  (0, 16)\t-0.02857142857142857\n",
      "  (0, 17)\t-0.02857142857142857\n",
      "  (0, 18)\t-0.02857142857142857\n",
      "  (0, 19)\t-0.02857142857142857\n",
      "  (0, 20)\t-0.02857142857142857\n",
      "  (0, 21)\t-0.02857142857142857\n",
      "  (0, 22)\t-0.02857142857142857\n",
      "  (0, 23)\t-0.02857142857142857\n",
      "  (0, 24)\t-0.02857142857142857\n",
      "  :\t:\n",
      "  (57345, 57345)\t1.0\n",
      "  (57346, 57346)\t1.0\n",
      "  (57346, 57347)\t-1.0\n",
      "  (57347, 57346)\t-1.0\n",
      "  (57347, 57347)\t1.0\n",
      "  (57348, 57348)\t1.0\n",
      "  (57348, 57349)\t-1.0\n",
      "  (57349, 57348)\t-1.0\n",
      "  (57349, 57349)\t1.0\n",
      "  (57350, 57350)\t1.0\n",
      "  (57350, 57351)\t-1.0\n",
      "  (57351, 57350)\t-1.0\n",
      "  (57351, 57351)\t1.0\n",
      "  (57352, 57352)\t1.0\n",
      "  (57352, 57353)\t-1.0\n",
      "  (57353, 57352)\t-1.0\n",
      "  (57353, 57353)\t1.0\n",
      "  (57354, 57354)\t1.0\n",
      "  (57354, 57355)\t-1.0\n",
      "  (57355, 57354)\t-1.0\n",
      "  (57355, 57355)\t1.0\n",
      "  (57356, 57356)\t1.0\n",
      "  (57356, 57357)\t-1.0\n",
      "  (57357, 57356)\t-1.0\n",
      "  (57357, 57357)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"begin\")\n",
    "# #2\n",
    "# deepwalk_embedding_file=\"embeddings/all_network_deepwalk128.txt\"\n",
    "# deepwalk_embeddings=extract_node2vec(input_path, deepwalk_params, deepwalk_embedding_file)\n",
    "\n",
    "# #3\n",
    "# LINE_embedding_file=\"embeddings/all_network_LINE128.txt\"\n",
    "# LINE_embeddings=extract_LINE(input_path, LINE_params, LINE_embedding_file)\n",
    "# #4内存不够\n",
    "# GraRep_embedding_file=\"embeddings/all_network_GraRep128.txt\"\n",
    "# GraRep_embeddings=extract_GraRep(input_path, GraRep_params, GraRep_embedding_file)\n",
    "#5\n",
    "LLE_embedding_file=\"embeddings/all_network_LLE128.txt\"\n",
    "LLE_embeddings=extract_LLE(input_path, LLE_params, LLE_embedding_file)\n",
    "# #6\n",
    "# HOPE_embedding_file=\"embeddings/all_network_HOPE128.txt\"\n",
    "# HOPE_embeddings=extract_HOPE(input_path, HOPE_params, HOPE_embedding_file)\n",
    "# #7\n",
    "# SDNE_embedding_file=\"embeddings/all_network_SDNE128.txt\"\n",
    "# SDNE_embeddings=extract_SDNE(input_path, SDNE_params, SDNE_embedding_file)\n",
    "# #8\n",
    "# LaplacianEigenmaps_embedding_file=\"embeddings/all_network_LaplacianEigenmaps128.txt\"\n",
    "# LaplacianEigenmaps_embeddings=extract_LaplacianEigenmaps(input_path, LaplacianEigenmaps_params, LaplacianEigenmaps_embedding_file)\n",
    "# #9\n",
    "# GraphFactorization_embedding_file=\"embeddings/all_network_GraphFactorization128.txt\"\n",
    "# GraphFactorization_embeddings=extract_GraphFactorization(input_path, GraphFactorization_params, GraphFactorization_embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T14:15:08.409866Z",
     "start_time": "2020-05-29T14:15:00.820Z"
    }
   },
   "outputs": [],
   "source": [
    "# # dis_gene_network.write\n",
    "# input_path=\"network_edgelist/all_network_edgelist.txt\"\n",
    "# all_network=Graph()\n",
    "# all_network.read_adjlist(filename=input_path)\n",
    "# #网络表征模型\n",
    "# node2vec_all = openne.node2vec.Node2vec(graph=all_network, path_length=walk_length,\n",
    "#                                   num_paths=number_walks, dim=representation_size,\n",
    "#                                   workers=workers, p=p, q=q, window=window_size)\n",
    "# node2vec_all.save_embeddings(\"embeddings/all_network_node2vec128.txt\")\n",
    "\n",
    "# node2vec_all=node2vec_all.vectors\n",
    "# print(type(node2vec_all))\n",
    "# nodes=np.array(list(node2vec_all.keys()))\n",
    "# all_network_node2vec_vecs=np.array(list(node2vec_all.values()))\n",
    "# # for node, vec in disease_network_node2vec.items():\n",
    "# #     diseases.append(node)\n",
    "# #     vecs.append(vecs)\n",
    "# print(nodes.shape)\n",
    "# print(all_network_node2vec_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T03:41:33.340548Z",
     "start_time": "2020-05-26T03:40:32.928192Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "Preprocess transition probs...\n",
      "Walk iteration:\n",
      "1 / 40\n",
      "2 / 40\n",
      "3 / 40\n",
      "4 / 40\n",
      "5 / 40\n",
      "6 / 40\n",
      "7 / 40\n",
      "8 / 40\n",
      "9 / 40\n",
      "10 / 40\n",
      "11 / 40\n",
      "12 / 40\n",
      "13 / 40\n",
      "14 / 40\n",
      "15 / 40\n",
      "16 / 40\n",
      "17 / 40\n",
      "18 / 40\n",
      "19 / 40\n",
      "20 / 40\n",
      "21 / 40\n",
      "22 / 40\n",
      "23 / 40\n",
      "24 / 40\n",
      "25 / 40\n",
      "26 / 40\n",
      "27 / 40\n",
      "28 / 40\n",
      "29 / 40\n",
      "30 / 40\n",
      "31 / 40\n",
      "32 / 40\n",
      "33 / 40\n",
      "34 / 40\n",
      "35 / 40\n",
      "36 / 40\n",
      "37 / 40\n",
      "38 / 40\n",
      "39 / 40\n",
      "40 / 40\n",
      "Learning representation...\n"
     ]
    }
   ],
   "source": [
    "# print(\"begin\")\n",
    "# # dis_gene_network.write\n",
    "# input_path=\"network_edgelist/dg_network_edgelist.txt\"\n",
    "# dg_network=Graph()\n",
    "# dg_network.read_edgelist(filename=input_path)\n",
    "# #网络表征模型\n",
    "# node2vec_dg = openne.node2vec.Node2vec(graph=dg_network, path_length=walk_length,\n",
    "#                                   num_paths=number_walks, dim=representation_size,\n",
    "#                                   workers=workers, p=p, q=q, window=window_size)\n",
    "# node2vec_dg.save_embeddings(\"embeddings/dg_network_node2vec128.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T02:23:07.715565Z",
     "start_time": "2020-05-26T02:23:07.430180Z"
    }
   },
   "outputs": [],
   "source": [
    "# edges_filename=\"network_edgelist/train_edges_func.txt\"\n",
    "# pos_edges,neg_edges=read_edges(edges_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T02:24:45.251056Z",
     "start_time": "2020-05-26T02:24:42.923255Z"
    }
   },
   "outputs": [],
   "source": [
    "# #边的特征\n",
    "# #提取正例特征\n",
    "# pos_features=[]\n",
    "# label=[]\n",
    "# for disease_id,gene_id in pos_edges:\n",
    "#     pos_features.append(np.hstack((node2vec_all[str(disease_id)],node2vec_all[str(gene_id)])))\n",
    "#     label.append(1)\n",
    "\n",
    "# #提取负例特征\n",
    "# neg_features=[]\n",
    "# for disease_id,gene_id in neg_edges:\n",
    "#     neg_features.append(np.hstack((node2vec_all[str(disease_id)],node2vec_all[str(gene_id)])))\n",
    "#     label.append(0)\n",
    "# train_features=pos_features+neg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T03:00:42.848151Z",
     "start_time": "2020-05-26T03:00:42.540835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "130820:256\n",
      "156984:256\n",
      "287804\n",
      "(287804, 256)\n"
     ]
    }
   ],
   "source": [
    "# print(\"begin\")\n",
    "# print('{}:{}'.format(len(pos_features),len(pos_features[0])))\n",
    "# print('{}:{}'.format(len(neg_features),len(neg_features[0])))\n",
    "# print(len(label))\n",
    "# print(np.array(train_features).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T03:04:15.246258Z",
     "start_time": "2020-05-26T03:01:05.616003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n2v_0</th>\n",
       "      <th>n2v_1</th>\n",
       "      <th>n2v_2</th>\n",
       "      <th>n2v_3</th>\n",
       "      <th>n2v_4</th>\n",
       "      <th>n2v_5</th>\n",
       "      <th>n2v_6</th>\n",
       "      <th>n2v_7</th>\n",
       "      <th>n2v_8</th>\n",
       "      <th>n2v_9</th>\n",
       "      <th>...</th>\n",
       "      <th>n2v_247</th>\n",
       "      <th>n2v_248</th>\n",
       "      <th>n2v_249</th>\n",
       "      <th>n2v_250</th>\n",
       "      <th>n2v_251</th>\n",
       "      <th>n2v_252</th>\n",
       "      <th>n2v_253</th>\n",
       "      <th>n2v_254</th>\n",
       "      <th>n2v_255</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003202</td>\n",
       "      <td>-0.140782</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>0.064413</td>\n",
       "      <td>0.045403</td>\n",
       "      <td>0.118346</td>\n",
       "      <td>-0.082164</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>0.251382</td>\n",
       "      <td>-0.216391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111878</td>\n",
       "      <td>-0.026656</td>\n",
       "      <td>-0.069604</td>\n",
       "      <td>0.257554</td>\n",
       "      <td>0.373072</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>0.245287</td>\n",
       "      <td>0.043335</td>\n",
       "      <td>0.266498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.158180</td>\n",
       "      <td>-0.074107</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>-0.023721</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.071516</td>\n",
       "      <td>-0.077766</td>\n",
       "      <td>0.027596</td>\n",
       "      <td>0.282734</td>\n",
       "      <td>-0.159644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150741</td>\n",
       "      <td>0.159942</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>0.080754</td>\n",
       "      <td>0.058067</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>-0.050465</td>\n",
       "      <td>0.223759</td>\n",
       "      <td>0.233387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.162158</td>\n",
       "      <td>-0.102947</td>\n",
       "      <td>0.204488</td>\n",
       "      <td>0.027205</td>\n",
       "      <td>0.012591</td>\n",
       "      <td>0.049558</td>\n",
       "      <td>-0.165420</td>\n",
       "      <td>0.060486</td>\n",
       "      <td>0.302477</td>\n",
       "      <td>-0.346868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122516</td>\n",
       "      <td>0.096530</td>\n",
       "      <td>-0.066120</td>\n",
       "      <td>-0.036690</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.149756</td>\n",
       "      <td>-0.092061</td>\n",
       "      <td>0.234985</td>\n",
       "      <td>0.311093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.074494</td>\n",
       "      <td>-0.068874</td>\n",
       "      <td>0.172986</td>\n",
       "      <td>-0.024724</td>\n",
       "      <td>0.171737</td>\n",
       "      <td>0.097275</td>\n",
       "      <td>-0.150305</td>\n",
       "      <td>0.180905</td>\n",
       "      <td>0.078419</td>\n",
       "      <td>-0.202960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>0.020131</td>\n",
       "      <td>-0.045608</td>\n",
       "      <td>0.035811</td>\n",
       "      <td>0.128828</td>\n",
       "      <td>-0.037315</td>\n",
       "      <td>-0.177486</td>\n",
       "      <td>0.178492</td>\n",
       "      <td>0.066715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.172494</td>\n",
       "      <td>-0.165400</td>\n",
       "      <td>0.175080</td>\n",
       "      <td>-0.010540</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-0.030470</td>\n",
       "      <td>-0.157295</td>\n",
       "      <td>0.086059</td>\n",
       "      <td>0.301881</td>\n",
       "      <td>-0.291420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052760</td>\n",
       "      <td>0.127906</td>\n",
       "      <td>0.037284</td>\n",
       "      <td>0.099079</td>\n",
       "      <td>0.230483</td>\n",
       "      <td>-0.084454</td>\n",
       "      <td>-0.217913</td>\n",
       "      <td>0.381856</td>\n",
       "      <td>0.311460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n2v_0     n2v_1     n2v_2     n2v_3     n2v_4     n2v_5     n2v_6  \\\n",
       "0 -0.003202 -0.140782  0.155315  0.064413  0.045403  0.118346 -0.082164   \n",
       "1 -0.158180 -0.074107  0.385100 -0.023721 -0.035587  0.071516 -0.077766   \n",
       "2 -0.162158 -0.102947  0.204488  0.027205  0.012591  0.049558 -0.165420   \n",
       "3 -0.074494 -0.068874  0.172986 -0.024724  0.171737  0.097275 -0.150305   \n",
       "4 -0.172494 -0.165400  0.175080 -0.010540  0.000172 -0.030470 -0.157295   \n",
       "\n",
       "      n2v_7     n2v_8     n2v_9  ...     n2v_247   n2v_248   n2v_249  \\\n",
       "0  0.009738  0.251382 -0.216391  ...   -0.111878 -0.026656 -0.069604   \n",
       "1  0.027596  0.282734 -0.159644  ...   -0.150741  0.159942 -0.075783   \n",
       "2  0.060486  0.302477 -0.346868  ...   -0.122516  0.096530 -0.066120   \n",
       "3  0.180905  0.078419 -0.202960  ...    0.009005  0.020131 -0.045608   \n",
       "4  0.086059  0.301881 -0.291420  ...   -0.052760  0.127906  0.037284   \n",
       "\n",
       "    n2v_250   n2v_251   n2v_252   n2v_253   n2v_254   n2v_255  label  \n",
       "0  0.257554  0.373072 -0.187672  0.245287  0.043335  0.266498      1  \n",
       "1  0.080754  0.058067  0.001418 -0.050465  0.223759  0.233387      1  \n",
       "2 -0.036690  0.181183 -0.149756 -0.092061  0.234985  0.311093      1  \n",
       "3  0.035811  0.128828 -0.037315 -0.177486  0.178492  0.066715      1  \n",
       "4  0.099079  0.230483 -0.084454 -0.217913  0.381856  0.311460      1  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"begin\")\n",
    "# #基于边的特征\n",
    "# feature_columns=['n2v_'+str(i) for i in range(representation_size*2)]\n",
    "# train_data=pd.DataFrame(train_features,columns=feature_columns)\n",
    "# train_data['label']=label\n",
    "# train_data.to_csv(\"train_data/allnet128_train_data.csv\",index = False)\n",
    "# train_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:OpenNE]",
   "language": "python",
   "name": "conda-env-OpenNE-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
